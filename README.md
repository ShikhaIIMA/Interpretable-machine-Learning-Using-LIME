# Interpretable-machine-Learning-Using-LIME
##Need for Interpretable and Explainable Machine Learning
This repository demonstrates use of Locally Interpretable Model Agnostic Explanations (LIME) to explain predictions of black-box models.
Machine Learning is used for many real-life prediction problems in healthcare, banking, finance and human resources. Some examples of these prediction problems are using transaction data to predict credit card fraud, using appli ation data to decide whether an applicant should be given a loan and using medical imagging data to diagnose a patient with a medical condition. While adopting any such system whose decisions directly impact humans, trust is a crucial factor in determining whether the decisions given by the machine learning models are used as a basisi to take any action. If the predictions given by models are explainable and can be interpreted by humans, it increases the trusttworthiness of the system.

##Black Box nature of Machine Learning models


**References**
1. https://christophm.github.io/interpretable-ml-book/
2.https://c3.ai/glossary/data-science/lime-local-interpretable-model-agnostic-explanations/
3. https://www.youtube.com/watch?v=hUnRCxnydCc
